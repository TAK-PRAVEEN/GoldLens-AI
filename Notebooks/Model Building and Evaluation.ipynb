{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93db2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3b77186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gold_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fb3b1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Day</th>\n",
       "      <th>...</th>\n",
       "      <th>Close_lag14</th>\n",
       "      <th>Close_lag30</th>\n",
       "      <th>MA_7</th>\n",
       "      <th>MA_14</th>\n",
       "      <th>MA_30</th>\n",
       "      <th>MA_60</th>\n",
       "      <th>MA_90</th>\n",
       "      <th>STD_7</th>\n",
       "      <th>STD_14</th>\n",
       "      <th>STD_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>2001-01-09</td>\n",
       "      <td>267.500000</td>\n",
       "      <td>267.500000</td>\n",
       "      <td>267.500000</td>\n",
       "      <td>267.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>269.700012</td>\n",
       "      <td>266.299988</td>\n",
       "      <td>268.457140</td>\n",
       "      <td>270.700003</td>\n",
       "      <td>270.463336</td>\n",
       "      <td>268.715000</td>\n",
       "      <td>270.119999</td>\n",
       "      <td>1.604014</td>\n",
       "      <td>2.851456</td>\n",
       "      <td>2.337034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>2001-01-10</td>\n",
       "      <td>264.700012</td>\n",
       "      <td>264.700012</td>\n",
       "      <td>264.700012</td>\n",
       "      <td>264.700012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>269.700012</td>\n",
       "      <td>270.100006</td>\n",
       "      <td>267.414285</td>\n",
       "      <td>270.342861</td>\n",
       "      <td>270.283336</td>\n",
       "      <td>268.520001</td>\n",
       "      <td>270.017777</td>\n",
       "      <td>1.250899</td>\n",
       "      <td>3.268905</td>\n",
       "      <td>2.563013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91</td>\n",
       "      <td>2001-01-11</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>272.500000</td>\n",
       "      <td>269.799988</td>\n",
       "      <td>266.785714</td>\n",
       "      <td>269.735718</td>\n",
       "      <td>270.090003</td>\n",
       "      <td>268.380001</td>\n",
       "      <td>269.858888</td>\n",
       "      <td>1.698456</td>\n",
       "      <td>3.609097</td>\n",
       "      <td>2.807793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92</td>\n",
       "      <td>2001-01-12</td>\n",
       "      <td>263.899994</td>\n",
       "      <td>263.899994</td>\n",
       "      <td>263.899994</td>\n",
       "      <td>263.899994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>273.700012</td>\n",
       "      <td>266.399994</td>\n",
       "      <td>266.199999</td>\n",
       "      <td>269.035716</td>\n",
       "      <td>270.006670</td>\n",
       "      <td>268.253334</td>\n",
       "      <td>269.713333</td>\n",
       "      <td>1.904379</td>\n",
       "      <td>3.729431</td>\n",
       "      <td>2.954360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93</td>\n",
       "      <td>2001-01-16</td>\n",
       "      <td>263.299988</td>\n",
       "      <td>263.299988</td>\n",
       "      <td>263.299988</td>\n",
       "      <td>263.299988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>273.700012</td>\n",
       "      <td>270.100006</td>\n",
       "      <td>265.628571</td>\n",
       "      <td>268.292858</td>\n",
       "      <td>269.780003</td>\n",
       "      <td>268.123334</td>\n",
       "      <td>269.574444</td>\n",
       "      <td>2.108488</td>\n",
       "      <td>3.764508</td>\n",
       "      <td>3.197783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date        Open        High         Low       Close  \\\n",
       "0          89  2001-01-09  267.500000  267.500000  267.500000  267.500000   \n",
       "1          90  2001-01-10  264.700012  264.700012  264.700012  264.700012   \n",
       "2          91  2001-01-11  264.000000  264.000000  264.000000  264.000000   \n",
       "3          92  2001-01-12  263.899994  263.899994  263.899994  263.899994   \n",
       "4          93  2001-01-16  263.299988  263.299988  263.299988  263.299988   \n",
       "\n",
       "   Volume  Month  Year  Day  ...  Close_lag14  Close_lag30        MA_7  \\\n",
       "0     0.0      1  2001    9  ...   269.700012   266.299988  268.457140   \n",
       "1     0.0      1  2001   10  ...   269.700012   270.100006  267.414285   \n",
       "2     0.0      1  2001   11  ...   272.500000   269.799988  266.785714   \n",
       "3     0.0      1  2001   12  ...   273.700012   266.399994  266.199999   \n",
       "4     0.0      1  2001   16  ...   273.700012   270.100006  265.628571   \n",
       "\n",
       "        MA_14       MA_30       MA_60       MA_90     STD_7    STD_14  \\\n",
       "0  270.700003  270.463336  268.715000  270.119999  1.604014  2.851456   \n",
       "1  270.342861  270.283336  268.520001  270.017777  1.250899  3.268905   \n",
       "2  269.735718  270.090003  268.380001  269.858888  1.698456  3.609097   \n",
       "3  269.035716  270.006670  268.253334  269.713333  1.904379  3.729431   \n",
       "4  268.292858  269.780003  268.123334  269.574444  2.108488  3.764508   \n",
       "\n",
       "     STD_30  \n",
       "0  2.337034  \n",
       "1  2.563013  \n",
       "2  2.807793  \n",
       "3  2.954360  \n",
       "4  3.197783  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df7e025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92d0e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date', 'Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76aceae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Month', 'Year', 'Day',\n",
       "       'DayOfWeek', 'DayOfYear', 'Quarter', 'IsMonthStart', 'IsMonthEnd',\n",
       "       'IsYearStart', 'IsYearEnd', 'Return', 'Volatility_7', 'Volatility_30',\n",
       "       'Trend_7', 'Trend_30', 'Close_lag1', 'Close_lag3', 'Close_lag7',\n",
       "       'Close_lag14', 'Close_lag30', 'MA_7', 'MA_14', 'MA_30', 'MA_60',\n",
       "       'MA_90', 'STD_7', 'STD_14', 'STD_30'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1dd79d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     52\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=\u001b[33m'\u001b[39m\u001b[33mmse\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Predictions\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     62\u001b[39m pred_scaled = model.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:889\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    887\u001b[39m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[32m    888\u001b[39m   initializers = []\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    891\u001b[39m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[32m    892\u001b[39m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[32m    893\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:696\u001b[39m, in \u001b[36mFunction._initialize\u001b[39m\u001b[34m(self, args, kwds, add_initializers_to)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28mself\u001b[39m._variable_creation_config = \u001b[38;5;28mself\u001b[39m._generate_scoped_tracing_options(\n\u001b[32m    692\u001b[39m     variable_capturing_scope,\n\u001b[32m    693\u001b[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_creator_scope\u001b[39m(*unused_args, **unused_kwds):\n\u001b[32m    701\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1060\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1057\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1059\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:599\u001b[39m, in \u001b[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m default_graph._variable_creator_scope(scope, priority=\u001b[32m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    596\u001b[39m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[32m    597\u001b[39m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[32m    598\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     out = \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[39m, in \u001b[36mpy_func_from_autograph.<locals>.autograph_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m     51\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:339\u001b[39m, in \u001b[36mconverted_call\u001b[39m\u001b[34m(f, args, kwargs, caller_fn_scope, options)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[32m    338\u001b[39m   logging.log(\u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: AutoGraph artifact\u001b[39m\u001b[33m'\u001b[39m, f)\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools.partial):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[39m, in \u001b[36m_call_unconverted\u001b[39m\u001b[34m(f, args, kwargs, options, update_cache)\u001b[39m\n\u001b[32m    456\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m f.\u001b[34m__self__\u001b[39m.call(args, kwargs)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f(*args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:133\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.multi_step_on_iterator\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@tf\u001b[39m.autograph.experimental.do_not_convert\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmulti_step_on_iterator\u001b[39m(iterator):\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps_per_execution == \u001b[32m1\u001b[39m:\n\u001b[32m    132\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tf.experimental.Optional.from_value(\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m             \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m         )\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n\u001b[32m    137\u001b[39m     empty_outputs = tf.experimental.Optional.empty(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:906\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[32m    903\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    904\u001b[39m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[32m    905\u001b[39m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m906\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    910\u001b[39m   bound_args = \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn.function_type.bind(\n\u001b[32m    911\u001b[39m       *args, **kwds\n\u001b[32m    912\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:132\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    130\u001b[39m args = args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[32m    131\u001b[39m kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m function = \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1060\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1057\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1059\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:599\u001b[39m, in \u001b[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m default_graph._variable_creator_scope(scope, priority=\u001b[32m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    596\u001b[39m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[32m    597\u001b[39m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[32m    598\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     out = \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[39m, in \u001b[36mpy_func_from_autograph.<locals>.autograph_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m     51\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[39m, in \u001b[36mconverted_call\u001b[39m\u001b[34m(f, args, kwargs, caller_fn_scope, options)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conversion.is_in_allowlist_cache(f, options):\n\u001b[32m    330\u001b[39m   logging.log(\u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: from cache\u001b[39m\u001b[33m'\u001b[39m, f)\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx.control_status_ctx().status == ag_ctx.Status.DISABLED:\n\u001b[32m    334\u001b[39m   logging.log(\u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: AutoGraph is disabled in context\u001b[39m\u001b[33m'\u001b[39m, f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[39m, in \u001b[36m_call_unconverted\u001b[39m\u001b[34m(f, args, kwargs, options, update_cache)\u001b[39m\n\u001b[32m    456\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m f.\u001b[34m__self__\u001b[39m.call(args, kwargs)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f(*args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:114\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;129m@tf\u001b[39m.autograph.experimental.do_not_convert\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mone_step_on_data\u001b[39m(data):\n\u001b[32m    113\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     outputs = reduce_per_replica(\n\u001b[32m    116\u001b[39m         outputs,\n\u001b[32m    117\u001b[39m         \u001b[38;5;28mself\u001b[39m.distribute_strategy,\n\u001b[32m    118\u001b[39m         reduction=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    119\u001b[39m     )\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1673\u001b[39m, in \u001b[36mStrategyBase.run\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1668\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scope():\n\u001b[32m   1669\u001b[39m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[32m   1670\u001b[39m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[32m   1671\u001b[39m   fn = autograph.tf_convert(\n\u001b[32m   1672\u001b[39m       fn, autograph_ctx.control_status_ctx(), convert_by_default=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1673\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extended\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3263\u001b[39m, in \u001b[36mStrategyExtendedV1.call_for_each_replica\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   3261\u001b[39m   kwargs = {}\n\u001b[32m   3262\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._container_strategy().scope():\n\u001b[32m-> \u001b[39m\u001b[32m3263\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4061\u001b[39m, in \u001b[36m_DefaultDistributionExtended._call_for_each_replica\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   4059\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[32m   4060\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m._container_strategy(), replica_id_in_sync_group=\u001b[32m0\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4061\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:58\u001b[39m, in \u001b[36mTensorFlowTrainer.train_step\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_has_training_arg:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m         y_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     60\u001b[39m         y_pred = \u001b[38;5;28mself\u001b[39m(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\models\\sequential.py:220\u001b[39m, in \u001b[36mSequential.call\u001b[39m\u001b[34m(self, inputs, training, mask, **kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training=\u001b[38;5;28;01mNone\u001b[39;00m, mask=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._functional:\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_functional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m     \u001b[38;5;66;03m# Fallback: Just apply the layer sequence.\u001b[39;00m\n\u001b[32m    225\u001b[39m     \u001b[38;5;66;03m# This typically happens if `inputs` is a nested struct.\u001b[39;00m\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m    227\u001b[39m         \u001b[38;5;66;03m# During each iteration, `inputs` are the inputs to `layer`, and\u001b[39;00m\n\u001b[32m    228\u001b[39m         \u001b[38;5;66;03m# `outputs` are the outputs of `layer` applied to `inputs`. At the\u001b[39;00m\n\u001b[32m    229\u001b[39m         \u001b[38;5;66;03m# end of each iteration `inputs` is set to `outputs` to prepare for\u001b[39;00m\n\u001b[32m    230\u001b[39m         \u001b[38;5;66;03m# the next layer.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\models\\functional.py:183\u001b[39m, in \u001b[36mFunctional.call\u001b[39m\u001b[34m(self, inputs, training, mask, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m             backend.set_keras_mask(x, mask)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\ops\\function.py:206\u001b[39m, in \u001b[36mFunction._run_through_graph\u001b[39m\u001b[34m(self, inputs, operation_fn, call_fn)\u001b[39m\n\u001b[32m    204\u001b[39m     operation = \u001b[38;5;28mself\u001b[39m._get_operation_for_node(node)\n\u001b[32m    205\u001b[39m     op = operation_fn(operation)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     outputs = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node.outputs, tree.flatten(outputs)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\models\\functional.py:644\u001b[39m, in \u001b[36moperation_fn.<locals>.call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    639\u001b[39m         name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(operation, \u001b[33m\"\u001b[39m\u001b[33m_call_context_args\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m    640\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    641\u001b[39m     ):\n\u001b[32m    642\u001b[39m         kwargs[name] = value\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:583\u001b[39m, in \u001b[36mLSTM.call\u001b[39m\u001b[34m(self, sequences, initial_state, mask, training)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequences, initial_state=\u001b[38;5;28;01mNone\u001b[39;00m, mask=\u001b[38;5;28;01mNone\u001b[39;00m, training=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m        \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_state\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:406\u001b[39m, in \u001b[36mRNN.call\u001b[39m\u001b[34m(self, sequences, initial_state, mask, training)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;66;03m# Prepopulate the dropout state so that the inner_loop is stateless\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[38;5;66;03m# this is particularly important for JAX backend.\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[38;5;28mself\u001b[39m._maybe_config_dropout_masks(\n\u001b[32m    403\u001b[39m     \u001b[38;5;28mself\u001b[39m.cell, sequences[:, \u001b[32m0\u001b[39m, :], initial_state\n\u001b[32m    404\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m last_output, outputs, states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m=\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m last_output = ops.cast(last_output, \u001b[38;5;28mself\u001b[39m.compute_dtype)\n\u001b[32m    413\u001b[39m outputs = ops.cast(outputs, \u001b[38;5;28mself\u001b[39m.compute_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:578\u001b[39m, in \u001b[36mLSTM.inner_loop\u001b[39m\u001b[34m(self, sequences, initial_state, mask, training)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_cudnn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    573\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33muse_cudnn=True was specified, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    574\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbut cuDNN is not supported for this layer configuration \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith this backend. Pass use_cudnn=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to fallback \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mto a non-cuDNN implementation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minner_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:346\u001b[39m, in \u001b[36mRNN.inner_loop\u001b[39m\u001b[34m(self, sequences, initial_state, mask, training)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tree.is_nested(initial_state):\n\u001b[32m    344\u001b[39m     initial_state = [initial_state]\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgo_backwards\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgo_backwards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43munroll\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43munroll\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mzero_output_for_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mzero_output_for_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_all_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py:262\u001b[39m, in \u001b[36mrnn\u001b[39m\u001b[34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[39m\n\u001b[32m    257\u001b[39m input_time_zero = tree.pack_sequence_as(\n\u001b[32m    258\u001b[39m     inputs, [inp[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m flattened_inputs]\n\u001b[32m    259\u001b[39m )\n\u001b[32m    260\u001b[39m \u001b[38;5;66;03m# output_time_zero is used to determine the cell output shape and its\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[38;5;66;03m# dtype.  the value is discarded.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m output_time_zero, _ = \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_time_zero\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minitial_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m output_ta_size = time_steps_t \u001b[38;5;28;01mif\u001b[39;00m return_all_outputs \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    267\u001b[39m output_ta = \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m    268\u001b[39m     tf.TensorArray(\n\u001b[32m    269\u001b[39m         dtype=out.dtype,\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tree.flatten(output_time_zero))\n\u001b[32m    275\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:338\u001b[39m, in \u001b[36mRNN.inner_loop.<locals>.step\u001b[39m\u001b[34m(inputs, states)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.backend() == \u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stateful:\n\u001b[32m    337\u001b[39m     states = tree.map_structure(ops.copy, states)\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m output, new_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcell_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tree.is_nested(new_states):\n\u001b[32m    340\u001b[39m     new_states = [new_states]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:279\u001b[39m, in \u001b[36mLSTMCell.call\u001b[39m\u001b[34m(self, inputs, states, training)\u001b[39m\n\u001b[32m    275\u001b[39m     inputs = inputs * dp_mask\n\u001b[32m    277\u001b[39m z = ops.matmul(inputs, \u001b[38;5;28mself\u001b[39m.kernel)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m z += \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_tm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrecurrent_kernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_bias:\n\u001b[32m    281\u001b[39m     z += \u001b[38;5;28mself\u001b[39m.bias\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\ops\\numpy.py:4211\u001b[39m, in \u001b[36mmatmul\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m   4209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x1, x2)):\n\u001b[32m   4210\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Matmul().symbolic_call(x1, x2)\n\u001b[32m-> \u001b[39m\u001b[32m4211\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py:520\u001b[39m, in \u001b[36mmatmul\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m    518\u001b[39m     output_type = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    519\u001b[39m x1 = tf.cast(x1, compute_dtype)\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m x2 = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_combined_batch_dimensions\u001b[39m(a, b, output_shape, fn_3d):\n\u001b[32m    523\u001b[39m     a_sparse = \u001b[38;5;28misinstance\u001b[39m(a, tf.SparseTensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1264\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1266\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1267\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1268\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1012\u001b[39m, in \u001b[36mcast\u001b[39m\u001b[34m(x, dtype, name)\u001b[39m\n\u001b[32m   1006\u001b[39m   x = indexed_slices.IndexedSlices(values_cast, x.indices, x.dense_shape)\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1008\u001b[39m   \u001b[38;5;66;03m# TODO(josh11b): If x is not already a Tensor, we could return\u001b[39;00m\n\u001b[32m   1009\u001b[39m   \u001b[38;5;66;03m# ops.convert_to_tensor(x, dtype=dtype, ...)  here, but that\u001b[39;00m\n\u001b[32m   1010\u001b[39m   \u001b[38;5;66;03m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[39;00m\n\u001b[32m   1011\u001b[39m   \u001b[38;5;66;03m# strings.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m   x = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m x.dtype.is_complex \u001b[38;5;129;01mand\u001b[39;00m base_type.is_floating:\n\u001b[32m   1014\u001b[39m     logging.warn(\n\u001b[32m   1015\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou are casting an input of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.dtype.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to an \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1016\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mincompatible dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_type.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.  This will \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdiscard the imaginary part and may not be what you \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mintended.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[39m, in \u001b[36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, **trace_kwargs):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:757\u001b[39m, in \u001b[36mconvert_to_tensor\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[32m    756\u001b[39m preferred_dtype = preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:209\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[39m\n\u001b[32m    207\u001b[39m overload = \u001b[38;5;28mgetattr\u001b[39m(value, \u001b[33m\"\u001b[39m\u001b[33m__tf_tensor__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m overload \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moverload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#  pylint: disable=not-callable\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m get(\u001b[38;5;28mtype\u001b[39m(value)):\n\u001b[32m    212\u001b[39m   \u001b[38;5;66;03m# If dtype is None but preferred_dtype is not None, we try to\u001b[39;00m\n\u001b[32m    213\u001b[39m   \u001b[38;5;66;03m# cast to preferred_dtype first.\u001b[39;00m\n\u001b[32m    214\u001b[39m   ret = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:84\u001b[39m, in \u001b[36mVariable.__tf_tensor__\u001b[39m\u001b[34m(self, dtype, name)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1264\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1266\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1267\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1268\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py:161\u001b[39m, in \u001b[36mconvert_to_tensor_v2_with_dispatch\u001b[39m\u001b[34m(value, dtype, dtype_hint, name)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m.tf_export(\u001b[33m\"\u001b[39m\u001b[33mconvert_to_tensor\u001b[39m\u001b[33m\"\u001b[39m, v1=[])\n\u001b[32m     97\u001b[39m \u001b[38;5;129m@dispatch\u001b[39m.add_dispatch_support\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[32m     99\u001b[39m     value, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    100\u001b[39m ) -> tensor_lib.Tensor:\n\u001b[32m    101\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[32m    102\u001b[39m \n\u001b[32m    103\u001b[39m \u001b[33;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m \u001b[33;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py:171\u001b[39m, in \u001b[36mconvert_to_tensor_v2\u001b[39m\u001b[34m(value, dtype, dtype_hint, name)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_hint\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[39m\n\u001b[32m    225\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    226\u001b[39m           _add_error_prefix(\n\u001b[32m    227\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for type \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret.dtype.base_dtype.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    231\u001b[39m               name=name))\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m   ret = \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[32m    237\u001b[39m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2378\u001b[39m, in \u001b[36m_dense_var_to_tensor\u001b[39m\u001b[34m(var, dtype, name, as_ref)\u001b[39m\n\u001b[32m   2377\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_dense_var_to_tensor\u001b[39m(var, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m, as_ref=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2378\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvar\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_dense_var_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1624\u001b[39m, in \u001b[36mBaseResourceVariable._dense_var_to_tensor\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1622\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_value().op.inputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:658\u001b[39m, in \u001b[36mBaseResourceVariable.value\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    656\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cached_value\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28;01mNone\u001b[39;00m, ignore_existing=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:843\u001b[39m, in \u001b[36mBaseResourceVariable._read_variable_op\u001b[39m\u001b[34m(self, no_copy)\u001b[39m\n\u001b[32m    841\u001b[39m       result = read_and_set_handle(no_copy)\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m   result = \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context.executing_eagerly():\n\u001b[32m    846\u001b[39m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[32m    847\u001b[39m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[32m    848\u001b[39m   record.record_operation(\n\u001b[32m    849\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mReadVariableOp\u001b[39m\u001b[33m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m.handle],\n\u001b[32m    850\u001b[39m       backward_function=\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[32m    851\u001b[39m       forward_function=\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:833\u001b[39m, in \u001b[36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[39m\u001b[34m(no_copy)\u001b[39m\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat.forward_compatible(\u001b[32m2022\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m3\u001b[39m):\n\u001b[32m    832\u001b[39m   gen_resource_variable_ops.disable_copy_on_read(\u001b[38;5;28mself\u001b[39m.handle)\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m result = \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m._dtype, \u001b[38;5;28mself\u001b[39m.handle, result)\n\u001b[32m    836\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:548\u001b[39m, in \u001b[36mread_variable_op\u001b[39m\u001b[34m(resource, dtype, name)\u001b[39m\n\u001b[32m    546\u001b[39m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[32m    547\u001b[39m dtype = _execute.make_type(dtype, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m _, _, _op, _outputs = \u001b[43m_op_def_library\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReadVariableOp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    550\u001b[39m _result = _outputs[:]\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _execute.must_record_gradient():\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:778\u001b[39m, in \u001b[36m_apply_op_helper\u001b[39m\u001b[34m(op_type_name, name, **keywords)\u001b[39m\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m g.as_default(), ops.name_scope(name) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[32m    777\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m fallback:\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     \u001b[43m_ExtractInputsAndAttrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_list_attr_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_type_attr_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                           \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[32m    782\u001b[39m                            default_type_attr_map, attrs)\n\u001b[32m    783\u001b[39m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:551\u001b[39m, in \u001b[36m_ExtractInputsAndAttrs\u001b[39m\u001b[34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[39m\n\u001b[32m    545\u001b[39m       values = ops.convert_to_tensor(\n\u001b[32m    546\u001b[39m           values,\n\u001b[32m    547\u001b[39m           name=input_arg.name,\n\u001b[32m    548\u001b[39m           as_ref=input_arg.is_ref,\n\u001b[32m    549\u001b[39m           preferred_dtype=default_dtype)\n\u001b[32m    550\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m     values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_arg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_arg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    558\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[39m, in \u001b[36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, **trace_kwargs):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:757\u001b[39m, in \u001b[36mconvert_to_tensor\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[32m    756\u001b[39m preferred_dtype = preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:209\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[39m\n\u001b[32m    207\u001b[39m overload = \u001b[38;5;28mgetattr\u001b[39m(value, \u001b[33m\"\u001b[39m\u001b[33m__tf_tensor__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m overload \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moverload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#  pylint: disable=not-callable\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m get(\u001b[38;5;28mtype\u001b[39m(value)):\n\u001b[32m    212\u001b[39m   \u001b[38;5;66;03m# If dtype is None but preferred_dtype is not None, we try to\u001b[39;00m\n\u001b[32m    213\u001b[39m   \u001b[38;5;66;03m# cast to preferred_dtype first.\u001b[39;00m\n\u001b[32m    214\u001b[39m   ret = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:651\u001b[39m, in \u001b[36m_EagerTensorBase.__tf_tensor__\u001b[39m\u001b[34m(self, dtype, name)\u001b[39m\n\u001b[32m    645\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m graph.building_function:\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    647\u001b[39m         _add_error_prefix(\n\u001b[32m    648\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAttempting to capture an EagerTensor without \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mbuilding a function.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    650\u001b[39m             name=name))\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcapture\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().__tf_tensor__(dtype, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:619\u001b[39m, in \u001b[36mFuncGraph.capture\u001b[39m\u001b[34m(self, tensor, name, shape)\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcapture\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, name=\u001b[38;5;28;01mNone\u001b[39;00m, shape=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_function_captures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\core\\function\\capture\\capture_container.py:141\u001b[39m, in \u001b[36mFunctionCaptures.capture_by_value\u001b[39m\u001b[34m(self, graph, tensor, name)\u001b[39m\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m graph_const\n\u001b[32m    140\u001b[39m   \u001b[38;5;66;03m# Large EagerTensors and resources are captured with Placeholder ops\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_placeholder_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tensor.graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m graph:\n\u001b[32m    144\u001b[39m   graph._validate_in_scope(tensor)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\core\\function\\capture\\capture_container.py:285\u001b[39m, in \u001b[36mFunctionCaptures._create_placeholder_helper\u001b[39m\u001b[34m(self, graph, tensor, name)\u001b[39m\n\u001b[32m    279\u001b[39m   composite_device_name = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    280\u001b[39m placeholder_ctx = trace_type.InternalPlaceholderContext(\n\u001b[32m    281\u001b[39m     graph,\n\u001b[32m    282\u001b[39m     with_none_control_dependencies=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    283\u001b[39m     composite_device_name=composite_device_name,\n\u001b[32m    284\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m placeholder = \u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplaceholder_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplaceholder_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[38;5;28mself\u001b[39m.add_or_replace(\n\u001b[32m    287\u001b[39m     key=\u001b[38;5;28mid\u001b[39m(tensor), external=tensor, internal=placeholder, is_by_ref=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    288\u001b[39m )\n\u001b[32m    289\u001b[39m graph.inputs.append(placeholder)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:1018\u001b[39m, in \u001b[36mTensorSpec.placeholder_value\u001b[39m\u001b[34m(self, placeholder_context)\u001b[39m\n\u001b[32m   1014\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m placeholder_context.with_none_control_dependencies:\n\u001b[32m   1015\u001b[39m   \u001b[38;5;66;03m# Note: setting ops.control_dependencies(None) ensures we always put\u001b[39;00m\n\u001b[32m   1016\u001b[39m   \u001b[38;5;66;03m# capturing placeholders outside of any control flow context.\u001b[39;00m\n\u001b[32m   1017\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m context_graph.control_dependencies(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1018\u001b[39m     placeholder = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_graph_placeholder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1020\u001b[39m   placeholder = \u001b[38;5;28mself\u001b[39m._graph_placeholder(context_graph, name=name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:1058\u001b[39m, in \u001b[36mTensorSpec._graph_placeholder\u001b[39m\u001b[34m(self, graph, name)\u001b[39m\n\u001b[32m   1056\u001b[39m attrs = {\u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m: dtype_value, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m: shape}\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m   op = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m   1059\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPlaceholder\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1062\u001b[39m   \u001b[38;5;66;03m# TODO(b/262413656) Sometimes parameter names are not valid op names, in\u001b[39;00m\n\u001b[32m   1063\u001b[39m   \u001b[38;5;66;03m# which case an unnamed placeholder is created instead. Update this logic\u001b[39;00m\n\u001b[32m   1064\u001b[39m   \u001b[38;5;66;03m# to sanitize the name instead of falling back on unnamed placeholders.\u001b[39;00m\n\u001b[32m   1065\u001b[39m   logging.warning(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:614\u001b[39m, in \u001b[36mFuncGraph._create_op_internal\u001b[39m\u001b[34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[39m\n\u001b[32m    612\u001b[39m   inp = \u001b[38;5;28mself\u001b[39m.capture(inp)\n\u001b[32m    613\u001b[39m   captured_inputs.append(inp)\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2726\u001b[39m, in \u001b[36mGraph._create_op_internal\u001b[39m\u001b[34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[39m\n\u001b[32m   2723\u001b[39m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[32m   2724\u001b[39m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[32m   2725\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mutation_lock():\n\u001b[32m-> \u001b[39m\u001b[32m2726\u001b[39m   ret = \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_node_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2734\u001b[39m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2735\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2736\u001b[39m   \u001b[38;5;28mself\u001b[39m._create_op_helper(ret, compute_device=compute_device)\n\u001b[32m   2737\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1221\u001b[39m, in \u001b[36mOperation.from_node_def\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1218\u001b[39m     control_input_ops.append(control_op)\n\u001b[32m   1220\u001b[39m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m c_op = \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[38;5;28mself\u001b[39m = Operation(c_op, SymbolicTensor)\n\u001b[32m   1223\u001b[39m \u001b[38;5;28mself\u001b[39m._init(g)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1078\u001b[39m, in \u001b[36m_create_c_op\u001b[39m\u001b[34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[39m\n\u001b[32m   1074\u001b[39m   pywrap_tf_session.TF_SetAttrValueProto(op_desc, compat.as_str(name),\n\u001b[32m   1075\u001b[39m                                          serialized)\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m   c_op = \u001b[43mpywrap_tf_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.InvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1080\u001b[39m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[32m   1081\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e.message)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# ---------------------------\n",
    "# Data Preparation\n",
    "# ---------------------------\n",
    "df = df.copy()\n",
    "prices = df['Close'].values.reshape(-1, 1)\n",
    "\n",
    "# Scale only the Close price for LSTM\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(prices)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, window):\n",
    "    X, y = [], []\n",
    "    for i in range(window, len(data)):\n",
    "        X.append(data[i-window:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 60  # use last 60 days\n",
    "X, y = create_sequences(scaled_data, window_size)\n",
    "\n",
    "# Split into train/test\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Reshape for LSTM [samples, timesteps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# ---------------------------\n",
    "# LSTM Model\n",
    "# ---------------------------\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ---------------------------\n",
    "# Training\n",
    "# ---------------------------\n",
    "history = model.fit(X_train, y_train, epochs=60, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# Predictions\n",
    "# ---------------------------\n",
    "pred_scaled = model.predict(X_test)\n",
    "pred = scaler.inverse_transform(pred_scaled)\n",
    "actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# ---------------------------\n",
    "# Evaluation\n",
    "# ---------------------------\n",
    "mae = mean_absolute_error(actual, pred)\n",
    "rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "r2 = r2_score(actual, pred)\n",
    "\n",
    "print(\"\\n📊 LSTM Model Performance:\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Visualization\n",
    "# ---------------------------\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(actual, label='Actual', color='blue')\n",
    "plt.plot(pred, label='Predicted', color='orange')\n",
    "plt.title('Gold Price Prediction using LSTM')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "joblib.dump(model, \"best_random_forest_gold_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282e618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m16,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,857</span> (116.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,857\u001b[0m (116.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,857</span> (116.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,857\u001b[0m (116.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "✅ Model structure image saved as 'lstm_model_structure.png'\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# LSTM Model Visualization\n",
    "# ---------------------------\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# ---------------------------\n",
    "# Example LSTM Model\n",
    "# ---------------------------\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# ---------------------------\n",
    "# Compile Model\n",
    "# ---------------------------\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ---------------------------\n",
    "# Display Model Summary\n",
    "# ---------------------------\n",
    "print(model.summary())\n",
    "\n",
    "# ---------------------------\n",
    "# Save Model Structure as Image\n",
    "# ---------------------------\n",
    "plot_model(\n",
    "    model,\n",
    "    to_file=\"lstm_model_structure.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    show_layer_activations=True,\n",
    "    dpi=200\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Model structure image saved as 'lstm_model_structure.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d38d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training LSTM Model...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - loss: 0.0015 - val_loss: 4.1046e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - loss: 2.7494e-04 - val_loss: 9.2741e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - loss: 2.0427e-04 - val_loss: 3.4274e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - loss: 1.7993e-04 - val_loss: 4.3090e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - loss: 1.3494e-04 - val_loss: 2.6117e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - loss: 1.2552e-04 - val_loss: 3.6990e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - loss: 1.1559e-04 - val_loss: 5.3679e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 64ms/step - loss: 1.0928e-04 - val_loss: 3.9171e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - loss: 9.5480e-05 - val_loss: 2.6730e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - loss: 1.0368e-04 - val_loss: 2.5900e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 73ms/step - loss: 9.2867e-05 - val_loss: 1.6921e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 112ms/step - loss: 8.5036e-05 - val_loss: 2.0896e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - loss: 7.9347e-05 - val_loss: 2.5075e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 108ms/step - loss: 8.6827e-05 - val_loss: 3.4871e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 109ms/step - loss: 8.9820e-05 - val_loss: 4.8224e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 108ms/step - loss: 7.9919e-05 - val_loss: 3.5888e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 115ms/step - loss: 7.6854e-05 - val_loss: 2.7254e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - loss: 7.9675e-05 - val_loss: 3.1609e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - loss: 8.8195e-05 - val_loss: 6.6320e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - loss: 7.3853e-05 - val_loss: 4.8174e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - loss: 7.4268e-05 - val_loss: 2.2204e-04\n",
      "\n",
      "🚀 Training BiLSTM Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 65ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - loss: 2.4472e-04 - val_loss: 6.9110e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - loss: 2.3651e-04 - val_loss: 9.5372e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - loss: 1.6187e-04 - val_loss: 1.5948e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - loss: 1.4601e-04 - val_loss: 1.1951e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - loss: 1.2932e-04 - val_loss: 1.6838e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - loss: 1.2400e-04 - val_loss: 1.6347e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 66ms/step - loss: 1.0039e-04 - val_loss: 1.5997e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 65ms/step - loss: 1.0132e-04 - val_loss: 1.4502e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - loss: 9.3337e-05 - val_loss: 1.9594e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - loss: 8.5377e-05 - val_loss: 1.9383e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - loss: 8.5959e-05 - val_loss: 1.4006e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - loss: 8.0391e-05 - val_loss: 1.4101e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - loss: 8.1293e-05 - val_loss: 4.1475e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - loss: 7.5569e-05 - val_loss: 1.7321e-04\n",
      "\n",
      "🚀 Training GRU Model...\n",
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 0.0020 - val_loss: 3.8111e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 76ms/step - loss: 2.6597e-04 - val_loss: 4.7407e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - loss: 2.1001e-04 - val_loss: 2.2245e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - loss: 1.5319e-04 - val_loss: 1.0203e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 76ms/step - loss: 1.3343e-04 - val_loss: 2.1824e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - loss: 1.1342e-04 - val_loss: 8.3353e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - loss: 1.0459e-04 - val_loss: 2.4835e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - loss: 8.9491e-05 - val_loss: 2.7285e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - loss: 9.1219e-05 - val_loss: 6.3591e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - loss: 8.7816e-05 - val_loss: 1.8821e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - loss: 8.2742e-05 - val_loss: 4.3043e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - loss: 7.6049e-05 - val_loss: 6.0183e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 76ms/step - loss: 7.7014e-05 - val_loss: 6.7817e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 73ms/step - loss: 7.9167e-05 - val_loss: 5.5074e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - loss: 6.9521e-05 - val_loss: 5.0961e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - loss: 7.9190e-05 - val_loss: 4.9022e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - loss: 6.9637e-05 - val_loss: 9.6541e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - loss: 7.6653e-05 - val_loss: 3.3387e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - loss: 6.6755e-05 - val_loss: 1.9309e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 5.9178e-05 - val_loss: 4.3721e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 6.4564e-05 - val_loss: 1.9853e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 6.3029e-05 - val_loss: 5.5306e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - loss: 5.9060e-05 - val_loss: 5.7051e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 5.7448e-05 - val_loss: 4.2813e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 6.8465e-05 - val_loss: 2.5448e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - loss: 6.3287e-05 - val_loss: 4.1296e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 6.6644e-05 - val_loss: 6.9130e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - loss: 5.8405e-05 - val_loss: 5.1673e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - loss: 6.4927e-05 - val_loss: 3.7490e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 6.8368e-05 - val_loss: 7.6274e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 7.0788e-05 - val_loss: 1.2108e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - loss: 6.5645e-05 - val_loss: 2.0624e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 65ms/step - loss: 5.7635e-05 - val_loss: 8.0893e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - loss: 5.1250e-05 - val_loss: 3.8240e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - loss: 6.2134e-05 - val_loss: 5.2496e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - loss: 6.0770e-05 - val_loss: 1.0499e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 76ms/step - loss: 5.5755e-05 - val_loss: 6.9714e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 76ms/step - loss: 5.3370e-05 - val_loss: 3.6464e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - loss: 5.2860e-05 - val_loss: 1.9137e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - loss: 5.8577e-05 - val_loss: 5.6765e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - loss: 5.5196e-05 - val_loss: 1.3667e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - loss: 5.7038e-05 - val_loss: 1.2994e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - loss: 5.5484e-05 - val_loss: 4.4577e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - loss: 6.1381e-05 - val_loss: 5.3107e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - loss: 5.1476e-05 - val_loss: 2.0183e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - loss: 5.1444e-05 - val_loss: 4.9059e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - loss: 5.9166e-05 - val_loss: 5.1870e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - loss: 5.3726e-05 - val_loss: 7.6201e-05\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot embed the 'svg' image format",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved model architecture for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in PNG and SVG formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpng_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msvg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# Usage:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[43msave_model_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLSTM\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m save_model_plot(bilstm, \u001b[33m\"\u001b[39m\u001b[33mBiLSTM\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    117\u001b[39m save_model_plot(gru, \u001b[33m\"\u001b[39m\u001b[33mGRU\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 111\u001b[39m, in \u001b[36msave_model_plot\u001b[39m\u001b[34m(model, name)\u001b[39m\n\u001b[32m    109\u001b[39m svg_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_STRUCT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_model_structure.svg\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    110\u001b[39m plot_model(model, to_file=png_path, show_shapes=\u001b[38;5;28;01mTrue\u001b[39;00m, show_layer_names=\u001b[38;5;28;01mTrue\u001b[39;00m, expand_nested=\u001b[38;5;28;01mTrue\u001b[39;00m, dpi=\u001b[32m100\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43msvg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_layer_names\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_nested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved model architecture for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in PNG and SVG formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpng_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msvg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\keras\\src\\utils\\model_visualization.py:518\u001b[39m, in \u001b[36mplot_model\u001b[39m\u001b[34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, show_layer_activations, show_trainable, **kwargs)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisplay\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mto_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    520\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\GoldLens-AI\\venv\\Lib\\site-packages\\IPython\\core\\display.py:1016\u001b[39m, in \u001b[36mImage.__init__\u001b[39m\u001b[34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28mself\u001b[39m.embed = embed \u001b[38;5;28;01mif\u001b[39;00m embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ACCEPTABLE_EMBEDDINGS:\n\u001b[32m-> \u001b[39m\u001b[32m1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot embed the \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m image format\u001b[39m\u001b[33m\"\u001b[39m % (\u001b[38;5;28mself\u001b[39m.format))\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embed:\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mself\u001b[39m._mimetype = \u001b[38;5;28mself\u001b[39m._MIMETYPES.get(\u001b[38;5;28mself\u001b[39m.format)\n",
      "\u001b[31mValueError\u001b[39m: Cannot embed the 'svg' image format"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# GOLD PRICE PREDICTION ENSEMBLE (LSTM + BiLSTM + GRU)\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# Load & Preprocess Data\n",
    "# -----------------------------\n",
    "# df = pd.read_csv(\"gold_price.csv\") \n",
    "df = df[['Close']].dropna()\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df[['Close']])\n",
    "\n",
    "time_steps = 60\n",
    "\n",
    "def create_sequences(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(time_steps, len(data)):\n",
    "        X.append(data[i - time_steps:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(scaled_data, time_steps)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Split data (80-20)\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# -----------------------------\n",
    "# Helper Functions\n",
    "# -----------------------------\n",
    "def build_lstm(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(128, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(64),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_bilstm(input_shape):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(128, return_sequences=True), input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        Bidirectional(LSTM(64)),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_gru(input_shape):\n",
    "    model = Sequential([\n",
    "        GRU(128, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        GRU(64),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Create folder to save model images\n",
    "os.makedirs(\"model_structures\", exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Training Each Model\n",
    "# -----------------------------\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    "\n",
    "print(\"🚀 Training LSTM Model...\")\n",
    "lstm = build_lstm((X_train.shape[1], 1))\n",
    "lstm.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "          epochs=100, batch_size=32, verbose=1, callbacks=callbacks)\n",
    "\n",
    "print(\"\\n🚀 Training BiLSTM Model...\")\n",
    "bilstm = build_bilstm((X_train.shape[1], 1))\n",
    "bilstm.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "            epochs=100, batch_size=32, verbose=1, callbacks=callbacks)\n",
    "\n",
    "print(\"\\n🚀 Training GRU Model...\")\n",
    "gru = build_gru((X_train.shape[1], 1))\n",
    "gru.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "         epochs=100, batch_size=32, verbose=1, callbacks=callbacks)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfaeecc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model architecture for LSTM in PNG and SVG formats: model_structures/LSTM_model_structure.png\n",
      "Saved model architecture for BiLSTM in PNG and SVG formats: model_structures/BiLSTM_model_structure.png\n",
      "Saved model architecture for GRU in PNG and SVG formats: model_structures/GRU_model_structure.png\n",
      "\n",
      "✅ Model architecture images saved in 'model_structures/' folder\n"
     ]
    }
   ],
   "source": [
    "MODEL_STRUCT_DIR = \"model_structures\"\n",
    "os.makedirs(MODEL_STRUCT_DIR, exist_ok=True)\n",
    "\n",
    "def save_model_plot(model, name):\n",
    "    \"\"\"Save both .png and .svg plots with all details.\"\"\"\n",
    "    png_path = f\"{MODEL_STRUCT_DIR}/{name}_model_structure.png\"\n",
    "    # svg_path = f\"{MODEL_STRUCT_DIR}/{name}_model_structure.svg\"\n",
    "    plot_model(model, to_file=png_path, show_shapes=True, show_layer_names=True, expand_nested=True, dpi=100)\n",
    "    # plot_model(model, to_file=svg_path, show_shapes=True, show_layer_names=True, expand_nested=True, dpi=100)\n",
    "    print(f\"Saved model architecture for {name} in PNG and SVG formats: {png_path}\")\n",
    "\n",
    "# Usage:\n",
    "save_model_plot(lstm, \"LSTM\")\n",
    "save_model_plot(bilstm, \"BiLSTM\")\n",
    "save_model_plot(gru, \"GRU\")\n",
    "\n",
    "print(\"\\n✅ Model architecture images saved in 'model_structures/' folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "206e18e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Predictions\n",
    "# -----------------------------\n",
    "pred_lstm = lstm.predict(X_test)\n",
    "pred_bilstm = bilstm.predict(X_test)\n",
    "pred_gru = gru.predict(X_test)\n",
    "\n",
    "# Ensemble average\n",
    "ensemble_pred = (0.2*pred_lstm + 0.4*pred_bilstm + 0.3*pred_gru)\n",
    "\n",
    "# Inverse scaling\n",
    "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "pred_lstm_actual = scaler.inverse_transform(pred_lstm)\n",
    "pred_bilstm_actual = scaler.inverse_transform(pred_bilstm)\n",
    "pred_gru_actual = scaler.inverse_transform(pred_gru)\n",
    "ensemble_actual = scaler.inverse_transform(ensemble_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efe24752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1804.80004883],\n",
       "        [1805.69995117],\n",
       "        [1781.90002441],\n",
       "        [1775.69995117],\n",
       "        [1814.09997559],\n",
       "        [1825.69995117],\n",
       "        [1836.80004883],\n",
       "        [1835.90002441],\n",
       "        [1861.80004883],\n",
       "        [1870.80004883]]),\n",
       " array([[1683.9753],\n",
       "        [1675.0647],\n",
       "        [1666.3414],\n",
       "        [1656.0374],\n",
       "        [1645.911 ],\n",
       "        [1641.1573],\n",
       "        [1639.4904],\n",
       "        [1640.2086],\n",
       "        [1641.4935],\n",
       "        [1645.7454]], dtype=float32),\n",
       " array([[120.82470703],\n",
       "        [130.63525391],\n",
       "        [115.55859375],\n",
       "        [119.66259766],\n",
       "        [168.18896484],\n",
       "        [184.54260254],\n",
       "        [197.30969238],\n",
       "        [195.69140625],\n",
       "        [220.30651855],\n",
       "        [225.0546875 ]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_actual[:10], ensemble_actual[:10], (y_test_actual[:10]-ensemble_actual[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "042ed97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 LSTM Performance:\n",
      "MAE: 43.70\n",
      "RMSE: 61.24\n",
      "R²: 0.9877\n",
      "\n",
      "📊 BiLSTM Performance:\n",
      "MAE: 27.45\n",
      "RMSE: 37.64\n",
      "R²: 0.9954\n",
      "\n",
      "📊 GRU Performance:\n",
      "MAE: 108.25\n",
      "RMSE: 124.50\n",
      "R²: 0.9492\n",
      "\n",
      "📊 Ensemble Performance:\n",
      "MAE: 229.42\n",
      "RMSE: 243.46\n",
      "R²: 0.8059\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Evaluation Function\n",
    "# -----------------------------\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n📊 {name} Performance:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# Evaluate all models\n",
    "results = {}\n",
    "results['LSTM'] = evaluate_model('LSTM', y_test_actual, pred_lstm_actual)\n",
    "results['BiLSTM'] = evaluate_model('BiLSTM', y_test_actual, pred_bilstm_actual)\n",
    "results['GRU'] = evaluate_model('GRU', y_test_actual, pred_gru_actual)\n",
    "results['Ensemble'] = evaluate_model('Ensemble', y_test_actual, ensemble_actual)\n",
    "\n",
    "# -----------------------------\n",
    "# Visualization\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(y_test_actual, color='blue', label='Actual')\n",
    "plt.plot(ensemble_actual, color='orange', label='Ensemble Predicted')\n",
    "plt.title('Gold Price Prediction - Ensemble (LSTM + BiLSTM + GRU)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e238cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a551ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
